server.port=9981
#使用maven的属性
spring.application.name=@project.description@
spring.boot.admin.url=http://localhost:8090
management.security.enabled=false


spring.datasource.url=jdbc:mysql://127.0.0.1/amoy?useUnicode=true&characterEncoding=utf-8
spring.datasource.username=root
spring.datasource.password=1234qwer

spring.datasource.driver-class-name=com.mysql.jdbc.Driver
#开启对sql语句的打印
spring.jpa.properties.hibernate.show_sql=true
spring.jpa.hibernate.ddl-auto=update




#============== kafka ===================
# 指定kafka 代理地址，可以多个
#brokerServer(kafka)ip地址,不需要把所有集群中的地址都写上，可是一个或一部分
spring.kafka.bootstrap-servers=192.168.1.177:9092

spring.kafka.listener.concurrency=10

#=============== provider  =======================

spring.kafka.producer.retries=0
# 每次批量发送消息的数量
spring.kafka.producer.batch-size=16384
spring.kafka.producer.buffer-memory=33554432

# 指定消息key和消息体的编解码方式
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer

#=============== consumer  =======================
# 指定默认消费者group id
spring.kafka.consumer.group-id=test-consumer-group
#设置使用最开始的offset偏移量为该group.id的最早。如果不设置，则会是latest即该topic最新一个消息的offset
#如果采用latest，消费者只能得道其启动后，生产者生产的消息
#What to do when there is no initial offset in Kafka or if the current offset does not exist any more on the server.
#spring.kafka.consumer.auto-offset-reset=latest
spring.kafka.consumer.auto-offset-reset=earliest
#自动提交offset
#设置自动提交偏移量(offset),由auto.commit.interval.ms控制提交频率
spring.kafka.consumer.enable-auto-commit=true
spring.kafka.consumer.auto-commit-interval=100

# 指定消息key和消息体的编解码方式
spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer


#spring.kafka.listener.concurrency

#先在KafkaListenerAnnotationBeanPostProcessor中扫描bean，然后注册到KafkaListenerEndpointRegistrar
#而KafkaListenerEndpointRegistrar在afterPropertiesSet的时候去创建MessageListenerContainer
#messageListener包含了原始endpoint携带的bean以及method转换成的InvocableHandlerMethod
#ConcurrentMessageListenerContainer这个衔接上，根据配置的spring.kafka.listener.concurrency来生成多个并发的KafkaMessageListenerContainer实例
#每个KafkaMessageListenerContainer都自己创建一个ListenerConsumer，然后自己创建一个独立的kafka consumer，每个ListenerConsumer在线程池里头运行，这样来实现并发
#每个ListenerConsumer里头都有一个recordsToProcess队列，从原始的kafka consumer poll出来的记录会放到这个队列里头，
#然后有一个ListenerInvoker线程循环超时等待从recordsToProcess取出记录，然后调用messageListener的onMessage方法(即KafkaListener注解标准的方法)
